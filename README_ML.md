# Minecraft Voxel Generation with DiT (Diffusion Transformer)

ä½¿ç”¨æœ€æ–°çš„Diffusion Transformer (DiT)æ¶æ„ç”Ÿæˆ16x16x16çš„Minecraftå»ºç­‘ç»“æ„ã€‚

## ğŸš€ ç‰¹æ€§

- **DiTæ¶æ„**: ä½¿ç”¨æœ€æ–°çš„Diffusion Transformeræ›¿ä»£ä¼ ç»ŸUNet
- **å‡½æ•°è°ƒç”¨**: ä½¿ç”¨Gemini 2.5 Proçš„Function Callingç”Ÿæˆç»“æ„åŒ–æ•°æ®é›†
- **3Dæ‰©æ•£æ¨¡å‹**: ä¸“ä¸º3Dä½“ç´ æ•°æ®è®¾è®¡çš„æ‰©æ•£æ¨¡å‹
- **é«˜æ•ˆè®­ç»ƒ**: æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒå’Œæ¢¯åº¦ç´¯ç§¯
- **çµæ´»é‡‡æ ·**: æ”¯æŒDDPMå’ŒDDIMé‡‡æ ·å™¨

## ğŸ“¦ å®‰è£…

```bash
# å®‰è£…MLè®­ç»ƒä¾èµ–
pip install -r requirements_ml.txt

# å¦‚æœä½¿ç”¨GPUï¼Œç¡®ä¿å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“Š æ•°æ®é›†ç”Ÿæˆ

### æ­¥éª¤1: ç”Ÿæˆæ•°æ®é›†

ä½¿ç”¨Gemini 2.5 Proç”Ÿæˆ1000ä¸ªè®­ç»ƒæ ·æœ¬ï¼š

```bash
python dataset_generator.py \
  --api-key YOUR_API_KEY \
  --output-dir dataset \
  --num-samples 1000 \
  --model gemini-2.0-flash-exp
```

**å‚æ•°è¯´æ˜**:
- `--api-key`: Google AI Studio APIå¯†é’¥
- `--output-dir`: æ•°æ®é›†è¾“å‡ºç›®å½•
- `--num-samples`: ç”Ÿæˆæ ·æœ¬æ•°é‡
- `--model`: ä½¿ç”¨çš„Geminiæ¨¡å‹ï¼ˆæ¨èä½¿ç”¨gemini-2.0-flash-expï¼Œé€Ÿåº¦å¿«æˆæœ¬ä½ï¼‰

**æ•°æ®é›†ç»“æ„**:
```
dataset/
â”œâ”€â”€ sample_0000/
â”‚   â”œâ”€â”€ data.json        # äººç±»å¯è¯»çš„JSONæ ¼å¼
â”‚   â””â”€â”€ voxels.npz       # è®­ç»ƒç”¨çš„å‹ç¼©æ ¼å¼
â”œâ”€â”€ sample_0001/
â”œâ”€â”€ ...
â””â”€â”€ metadata.json        # æ•°æ®é›†å…ƒä¿¡æ¯
```

### æ•°æ®é›†ç‰¹ç‚¹

1. **å¤šæ ·æ€§**: åŒ…å«æˆ¿å±‹ã€å¡”ã€é›•å¡‘ã€æ ‘æœ¨ç­‰å¤šç§å»ºç­‘ç±»å‹
2. **ç»“æ„åŒ–è¾“å‡º**: ä½¿ç”¨å‡½æ•°è°ƒç”¨ç¡®ä¿AIè¿”å›æ­£ç¡®æ ¼å¼ï¼Œé¿å…å¯¹è¯å¼è¾“å‡º
3. **æ–¹å—å­—å…¸å‚è€ƒ**: AIä¼šå‚è€ƒMinecraftæ–¹å—IDå­—å…¸ç”ŸæˆçœŸå®çš„å»ºç­‘
4. **è‡ªåŠ¨é‡è¯•**: é‡åˆ°API 429é”™è¯¯ä¼šè‡ªåŠ¨é‡è¯•ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 

## ğŸ‹ï¸ æ¨¡å‹è®­ç»ƒ

### DiTæ¨¡å‹æ¶æ„é€‰æ‹©

æä¾›ä¸‰ç§æ¨¡å‹å¤§å°ï¼š

| æ¨¡å‹ | å‚æ•°é‡ | Hidden Size | Depth | Heads | æ¨èç”¨é€” |
|------|--------|-------------|-------|-------|----------|
| DiT-Small | ~33M | 384 | 12 | 6 | å¿«é€Ÿå®éªŒ |
| DiT-Base | ~86M | 512 | 16 | 8 | å¹³è¡¡æ€§èƒ½ |
| DiT-Large | ~458M | 768 | 24 | 12 | æœ€ä½³è´¨é‡ |

### æ­¥éª¤2: è®­ç»ƒæ¨¡å‹

#### åŸºç¡€è®­ç»ƒï¼ˆå•GPUï¼‰

```bash
python train.py \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size small \
  --batch-size 8 \
  --epochs 100 \
  --lr 1e-4 \
  --use-amp \
  --save-every 500
```

#### æ¨èé…ç½®ï¼ˆGPUæœåŠ¡å™¨ï¼‰

```bash
# ä½¿ç”¨Baseæ¨¡å‹ï¼Œæ··åˆç²¾åº¦è®­ç»ƒ
python train.py \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size base \
  --batch-size 16 \
  --epochs 200 \
  --lr 1e-4 \
  --weight-decay 0.01 \
  --grad-clip 1.0 \
  --use-amp \
  --num-workers 8 \
  --save-every 1000
```

#### é«˜ç«¯é…ç½®ï¼ˆå¤šGPU/A100ï¼‰

```bash
# Largeæ¨¡å‹ï¼Œæ›´å¤§batch size
python train.py \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size large \
  --batch-size 32 \
  --epochs 300 \
  --lr 5e-5 \
  --use-amp \
  --num-workers 16
```

**è®­ç»ƒå‚æ•°è¯´æ˜**:
- `--model-size`: æ¨¡å‹å¤§å°ï¼ˆsmall/base/largeï¼‰
- `--batch-size`: æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼‰
- `--epochs`: è®­ç»ƒè½®æ•°
- `--lr`: å­¦ä¹ ç‡
- `--use-amp`: å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœæ˜¾å­˜ï¼ŒåŠ é€Ÿè®­ç»ƒï¼‰
- `--grad-clip`: æ¢¯åº¦è£å‰ªé˜ˆå€¼
- `--save-every`: æ¯Nä¸ªbatchä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹

### ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

```bash
python train.py \
  --resume outputs/checkpoints/latest.pt \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size small
```

## ğŸ¨ ç”Ÿæˆæ–°å»ºç­‘

### æ­¥éª¤3: æ¨ç†ç”Ÿæˆ

```bash
# ä½¿ç”¨DDIMå¿«é€Ÿé‡‡æ ·ï¼ˆæ¨èï¼‰
python inference.py \
  --checkpoint outputs/checkpoints/latest.pt \
  --model-size small \
  --num-samples 10 \
  --sampler ddim \
  --num-steps 50 \
  --output-dir generated

# ä½¿ç”¨DDPMå®Œæ•´é‡‡æ ·ï¼ˆè´¨é‡æ›´é«˜ä½†æ›´æ…¢ï¼‰
python inference.py \
  --checkpoint outputs/final_model.pt \
  --model-size small \
  --num-samples 5 \
  --sampler ddpm \
  --output-dir generated
```

**æ¨ç†å‚æ•°**:
- `--checkpoint`: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
- `--num-samples`: ç”Ÿæˆæ ·æœ¬æ•°é‡
- `--sampler`: é‡‡æ ·å™¨ç±»å‹ï¼ˆddimæ¨èï¼Œæ›´å¿«ï¼‰
- `--num-steps`: DDIMé‡‡æ ·æ­¥æ•°ï¼ˆ50é€šå¸¸è¶³å¤Ÿï¼Œè¶Šå¤§è´¨é‡è¶Šå¥½ä½†è¶Šæ…¢ï¼‰
- `--batch-size`: æ‰¹é‡ç”Ÿæˆå¤§å°

### ç”Ÿæˆç»“æœ

ç”Ÿæˆçš„æ–‡ä»¶ä¿å­˜åœ¨`generated/`ç›®å½•ï¼š
```
generated/
â”œâ”€â”€ sample_0000.json    # JSONæ ¼å¼schematic
â”œâ”€â”€ sample_0000.npz     # NPZæ ¼å¼ï¼ˆå¯ç›´æ¥åŠ è½½ï¼‰
â”œâ”€â”€ sample_0001.json
â””â”€â”€ ...
```

## ğŸ”§ å·¥ä½œæµç¨‹ç¤ºä¾‹

### å®Œæ•´æµç¨‹ï¼ˆä»é›¶å¼€å§‹ï¼‰

```bash
# 1. ç”Ÿæˆæ•°æ®é›†ï¼ˆçº¦30åˆ†é’Ÿï¼Œ1000æ ·æœ¬ï¼‰
python dataset_generator.py \
  --api-key YOUR_API_KEY \
  --num-samples 1000

# 2. è®­ç»ƒæ¨¡å‹ï¼ˆGPUæœåŠ¡å™¨ä¸Šï¼Œçº¦2-8å°æ—¶ï¼‰
python train.py \
  --model-size base \
  --batch-size 16 \
  --epochs 100 \
  --use-amp

# 3. ç”Ÿæˆæ–°å»ºç­‘
python inference.py \
  --checkpoint outputs/checkpoints/latest.pt \
  --model-size base \
  --num-samples 20 \
  --sampler ddim
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¼šä¿å­˜ï¼š
- **æ£€æŸ¥ç‚¹**: `outputs/checkpoints/` 
- **é…ç½®æ–‡ä»¶**: `outputs/config.json`
- **æœ€ç»ˆæ¨¡å‹**: `outputs/final_model.pt`

ç›‘æ§è®­ç»ƒlossï¼š
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f outputs/train.log

# å¦‚æœå®‰è£…äº†tensorboard
tensorboard --logdir outputs/logs
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### GPUå†…å­˜ä¼˜åŒ–

å¦‚æœé‡åˆ°OOMé”™è¯¯ï¼š
1. å‡å°`--batch-size`
2. ä½¿ç”¨`--use-amp`å¯ç”¨æ··åˆç²¾åº¦
3. å‡å°‘`--num-workers`
4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆsmallè€Œä¸æ˜¯baseï¼‰

### è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–

1. **ä½¿ç”¨DDIMé‡‡æ ·**: æ¯”DDPMå¿«20å€ï¼Œè´¨é‡ç›¸è¿‘
2. **æ··åˆç²¾åº¦è®­ç»ƒ**: å¯ç”¨`--use-amp`
3. **å¢åŠ batch size**: å……åˆ†åˆ©ç”¨GPU
4. **å¤šworkeræ•°æ®åŠ è½½**: è®¾ç½®`--num-workers=8`

### ç”Ÿæˆè´¨é‡ä¼˜åŒ–

1. **å¢åŠ è®­ç»ƒepoch**: è‡³å°‘100ä¸ªepoch
2. **ä½¿ç”¨æ›´å¤§æ¨¡å‹**: baseæˆ–large
3. **å¢åŠ æ•°æ®é›†å¤§å°**: 2000-5000æ ·æœ¬æ›´å¥½
4. **è°ƒæ•´é‡‡æ ·æ­¥æ•°**: DDIMä½¿ç”¨50-100æ­¥

## ğŸ› å¸¸è§é—®é¢˜

### Q: API 429é”™è¯¯

A: è„šæœ¬ä¼šè‡ªåŠ¨é‡è¯•ã€‚å¦‚æœé¢‘ç¹é‡åˆ°ï¼Œå¯ä»¥ï¼š
- å¢åŠ é‡‡æ ·é—´éš”æ—¶é—´
- ä½¿ç”¨å¤šä¸ªAPIå¯†é’¥è½®æ¢
- ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆgemini-2.0-flash-expï¼‰

### Q: è®­ç»ƒlossä¸ä¸‹é™

A: æ£€æŸ¥ï¼š
- æ•°æ®é›†è´¨é‡ï¼ˆæ˜¯å¦æœ‰è¶³å¤Ÿå¤šæ ·æœ¬ï¼‰
- å­¦ä¹ ç‡ï¼ˆå°è¯•1e-4åˆ°1e-5ï¼‰
- æ¨¡å‹å¤§å°ï¼ˆå¯èƒ½éœ€è¦æ›´å¤§æ¨¡å‹ï¼‰

### Q: ç”Ÿæˆç»“æœä¸å¥½

A: 
- è®­ç»ƒæ›´å¤šepochsï¼ˆè‡³å°‘100ï¼‰
- å¢åŠ æ•°æ®é›†å¤§å°å’Œå¤šæ ·æ€§
- ä½¿ç”¨DDIMé‡‡æ ·å¹¶å¢åŠ æ­¥æ•°
- å°è¯•æ›´å¤§çš„æ¨¡å‹

## ğŸ“š æŠ€æœ¯ç»†èŠ‚

### DiTæ¶æ„

åŸºäºè®ºæ–‡ "Scalable Diffusion Models with Transformers" (2023):
- ä½¿ç”¨Transformeræ›¿ä»£ä¼ ç»ŸUNet
- Adaptive Layer Normalizationæ¡ä»¶åŒ–æ—¶é—´æ­¥
- 3D Patch Embeddingå¤„ç†ä½“ç´ æ•°æ®
- æ›´å¥½çš„å¯æ‰©å±•æ€§å’Œæ€§èƒ½

### æ‰©æ•£è¿‡ç¨‹

- **è®­ç»ƒ**: å­¦ä¹ é¢„æµ‹æ·»åŠ åˆ°æ•°æ®çš„å™ªå£°
- **é‡‡æ ·**: ä»éšæœºå™ªå£°é€æ­¥å»å™ªç”Ÿæˆç»“æ„
- **DDPM**: åŸå§‹é‡‡æ ·ç®—æ³•ï¼Œ1000æ­¥
- **DDIM**: ç¡®å®šæ€§é‡‡æ ·ï¼Œå¯ç”¨50æ­¥è¾¾åˆ°ç›¸ä¼¼è´¨é‡

### æ•°æ®æ ¼å¼

ä½“ç´ æ•°æ®ï¼š`(D, H, W, 2)` å…¶ä¸­ï¼š
- D, H, W = 16 (ä½“ç´ åˆ†è¾¨ç‡)
- é€šé“0: block_id (æ–¹å—ç±»å‹)
- é€šé“1: meta_data (æ–¹å—å˜ä½“)

## ğŸ¤ è¿›é˜¶ä½¿ç”¨

### è‡ªå®šä¹‰æ•°æ®é›†

ä¿®æ”¹`dataset_generator.py`ä¸­çš„`BUILDING_PROMPTS`æ·»åŠ æ–°å»ºç­‘ç±»å‹ï¼š

```python
BUILDING_PROMPTS = [
    "Your custom prompt 1",
    "Your custom prompt 2",
    # ...
]
```

### æ¡ä»¶ç”Ÿæˆï¼ˆTODOï¼‰

æœªæ¥å¯ä»¥æ·»åŠ æ–‡æœ¬æ¡ä»¶ï¼š
- ä¿®æ”¹DiTæ¨¡å‹æ·»åŠ æ–‡æœ¬ç¼–ç å™¨
- åœ¨è®­ç»ƒæ—¶ä½¿ç”¨promptä½œä¸ºæ¡ä»¶
- æ¨ç†æ—¶æä¾›æ–‡æœ¬æè¿°ç”Ÿæˆå¯¹åº”å»ºç­‘

## ğŸ“ å¼•ç”¨

å¦‚æœä½¿ç”¨æ­¤ä»£ç ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{peebles2023dit,
  title={Scalable Diffusion Models with Transformers},
  author={Peebles, William and Xie, Saining},
  journal={arXiv preprint arXiv:2212.09748},
  year={2023}
}
```

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ™ è‡´è°¢

- DiTè®ºæ–‡å’Œå®ç°
- Google Gemini API
- Minecraftç¤¾åŒº
