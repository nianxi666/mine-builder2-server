# ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼šMinecraft 16x16x16 DiTè®­ç»ƒç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„AIæ¨¡å‹è®­ç»ƒç³»ç»Ÿï¼Œç”¨äºç”ŸæˆMinecraft 16x16x16 schematicå»ºç­‘ã€‚

## ğŸ“‹ ç³»ç»Ÿæ¦‚è¿°

- **æ¨¡å‹æ¶æ„**: Diffusion Transformer (DiT) - æœ€æ–°çš„æ‰©æ•£æ¨¡å‹æ¶æ„
- **æ•°æ®å¤§å°**: 16x16x16 ä½“ç´ 
- **æ•°æ®é›†**: 1000ä¸ªæ ·æœ¬ï¼ˆå·²ç”Ÿæˆï¼‰
- **è®­ç»ƒ**: æ”¯æŒGPUåŠ é€Ÿï¼Œæ··åˆç²¾åº¦è®­ç»ƒ
- **æ¨ç†**: DDPM/DDIMé‡‡æ ·å™¨

## ğŸ¯ æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒæ–‡ä»¶
- `dit_model.py` - DiTæ¨¡å‹å®šä¹‰ï¼ˆ3D Transformeræ‰©æ•£æ¨¡å‹ï¼‰
- `train.py` - è®­ç»ƒè„šæœ¬
- `inference.py` - æ¨ç†ç”Ÿæˆè„šæœ¬

### æ•°æ®é›†ç”Ÿæˆ
- `create_synthetic_dataset.py` - åˆæˆæ•°æ®é›†ç”Ÿæˆå™¨ï¼ˆæ¨èï¼Œå¿«é€Ÿï¼‰
- `dataset_generator_simple.py` - ä½¿ç”¨Gemini APIç”Ÿæˆï¼ˆéœ€APIå¯†é’¥ï¼‰
- `dataset_generator.py` - å®Œæ•´ç‰ˆï¼ˆä½¿ç”¨å‡½æ•°è°ƒç”¨ï¼‰

### è¾…åŠ©æ–‡ä»¶
- `test_system.py` - ç³»ç»Ÿæµ‹è¯•è„šæœ¬
- `run_pipeline.sh` - å®Œæ•´æµç¨‹è„šæœ¬
- `quick_start.sh` - å¿«é€Ÿæµ‹è¯•è„šæœ¬
- `README_ML.md` - è¯¦ç»†æ–‡æ¡£

## âš¡ å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥ï¼‰

### æ–¹æ¡ˆA: ä½¿ç”¨å·²ç”Ÿæˆçš„åˆæˆæ•°æ®é›†ï¼ˆæ¨èï¼‰

æ•°æ®é›†å·²ç»ç”Ÿæˆåœ¨ `dataset/` ç›®å½•ï¼ˆ1000ä¸ªæ ·æœ¬ï¼‰ï¼

#### æ­¥éª¤1: æµ‹è¯•ç³»ç»Ÿ
```bash
python3 test_system.py
```

#### æ­¥éª¤2: å¼€å§‹è®­ç»ƒï¼ˆGPUæ¨èï¼‰
```bash
# å°æ¨¡å‹å¿«é€Ÿæµ‹è¯•ï¼ˆ5-10åˆ†é’Ÿï¼‰
python3 train.py \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size small \
  --batch-size 8 \
  --epochs 10 \
  --use-amp

# å®Œæ•´è®­ç»ƒï¼ˆå‡ å°æ—¶ï¼‰
python3 train.py \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size small \
  --batch-size 16 \
  --epochs 100 \
  --use-amp
```

#### æ­¥éª¤3: ç”Ÿæˆæ–°å»ºç­‘
```bash
python3 inference.py \
  --checkpoint outputs/checkpoints/latest.pt \
  --model-size small \
  --num-samples 10 \
  --sampler ddim \
  --num-steps 50
```

### æ–¹æ¡ˆB: ä½¿ç”¨Gemini APIç”ŸæˆçœŸå®æ•°æ®

éœ€è¦Google AI Studio APIå¯†é’¥ï¼ˆå·²æä¾›ï¼‰ï¼š

```bash
# ç”Ÿæˆ1000ä¸ªæ ·æœ¬ï¼ˆçº¦30-60åˆ†é’Ÿï¼‰
python3 dataset_generator_simple.py \
  --api-key AIzaSyB3xn379AZKVmCEIywishHGo_57GDj1o9A \
  --output-dir dataset_gemini \
  --num-samples 1000

# ç„¶åä½¿ç”¨ä¸Šé¢çš„è®­ç»ƒå‘½ä»¤ï¼Œä¿®æ”¹ --dataset-dir ä¸º dataset_gemini
```

## ğŸ’» è¿œç¨‹GPUè®­ç»ƒ

### SSHè¿æ¥åçš„è®¾ç½®

```bash
# 1. å…‹éš†æˆ–ä¸Šä¼ ä»£ç 
cd /path/to/project

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv_ml
source venv_ml/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install torch torchvision google-generativeai tqdm numpy

# 4. ç”Ÿæˆæˆ–ä¸Šä¼ æ•°æ®é›†
# é€‰é¡¹A: å¿«é€Ÿç”Ÿæˆåˆæˆæ•°æ®
python3 create_synthetic_dataset.py --num-samples 1000

# é€‰é¡¹B: ä½¿ç”¨Geminiç”Ÿæˆ
python3 dataset_generator_simple.py --num-samples 1000

# 5. å¼€å§‹è®­ç»ƒ
python3 train.py \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size base \
  --batch-size 32 \
  --epochs 200 \
  --use-amp \
  --num-workers 8

# 6. åå°è¿è¡Œï¼ˆæ¨èï¼‰
nohup python3 train.py \
  --dataset-dir dataset \
  --output-dir outputs \
  --model-size base \
  --batch-size 32 \
  --epochs 200 \
  --use-amp > training.log 2>&1 &

# ç›‘æ§è®­ç»ƒ
tail -f training.log
```

### GPUè¦æ±‚

- **æœ€å°**: 6GB VRAMï¼ˆsmallæ¨¡å‹ï¼Œbatch_size=4ï¼‰
- **æ¨è**: 16GB VRAMï¼ˆbaseæ¨¡å‹ï¼Œbatch_size=16ï¼‰
- **æœ€ä½³**: 24GB+ VRAMï¼ˆlargeæ¨¡å‹ï¼Œbatch_size=32ï¼‰

## ğŸ“ æ•°æ®é›†ä¿¡æ¯

### å½“å‰æ•°æ®é›†ï¼ˆsyntheticï¼‰
- **ä½ç½®**: `./dataset/`
- **æ ·æœ¬æ•°**: 1000
- **ç±»å‹**: åˆæˆè§„åˆ™å»ºç­‘
- **åŒ…å«**: ç«‹æ–¹ä½“ã€å¡”ã€é‡‘å­—å¡”ã€æˆ¿å±‹ã€æ ‘ã€å¢™ã€æ‹±é—¨ç­‰

### æ•°æ®æ ¼å¼
æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
- `data.json` - JSONæ ¼å¼ï¼Œäººç±»å¯è¯»
- `voxels.npz` - NumPyå‹ç¼©æ ¼å¼ï¼Œè®­ç»ƒä½¿ç”¨
  - voxels: (16, 16, 16, 2) - [block_id, meta_data]
  - prompt: æ–‡æœ¬æè¿°

## ğŸ® æ¨¡å‹é…ç½®

### DiT-Smallï¼ˆæ¨èå¼€å§‹ï¼‰
- å‚æ•°: ~33M
- Hidden size: 384
- Layers: 12
- è®­ç»ƒæ—¶é—´: 2-4å°æ—¶ï¼ˆ1000æ ·æœ¬ï¼Œ100 epochsï¼ŒGTX 1080ï¼‰

### DiT-Base
- å‚æ•°: ~86M
- Hidden size: 512
- Layers: 16
- è®­ç»ƒæ—¶é—´: 4-8å°æ—¶

### DiT-Large
- å‚æ•°: ~458M
- Hidden size: 768
- Layers: 24
- è®­ç»ƒæ—¶é—´: 8-16å°æ—¶

## ğŸ” æ£€æŸ¥è®­ç»ƒè¿›åº¦

```bash
# æŸ¥çœ‹checkpoints
ls -lh outputs/checkpoints/

# æœ€æ–°çš„checkpoint
ls -lh outputs/checkpoints/latest.pt

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -50 training.log

# æ£€æŸ¥ç”Ÿæˆçš„æ ·æœ¬
ls -lh generated/
```

## ğŸ¨ ç”Ÿæˆç»“æœ

ç”Ÿæˆçš„å»ºç­‘ä¿å­˜åœ¨ `generated/` ç›®å½•ï¼š

```bash
generated/
â”œâ”€â”€ sample_0000.json    # JSONæ ¼å¼
â”œâ”€â”€ sample_0000.npz     # NPZæ ¼å¼
â”œâ”€â”€ sample_0001.json
â””â”€â”€ ...
```

### æŸ¥çœ‹ç”Ÿæˆç»“æœ
```python
import json
import numpy as np

# è¯»å–JSON
with open('generated/sample_0000.json') as f:
    data = json.load(f)
    print(f"Prompt: {data['prompt']}")
    print(f"Blocks: {len(data['schematic']['voxels'])}")

# è¯»å–NPZ
data = np.load('generated/sample_0000.npz', allow_pickle=True)
voxels = data['voxels']  # (16, 16, 16, 2)
print(f"Shape: {voxels.shape}")
```

## âš™ï¸ è®­ç»ƒå‚æ•°è°ƒä¼˜

### æé«˜è´¨é‡
```bash
python3 train.py \
  --model-size base \        # ä½¿ç”¨æ›´å¤§æ¨¡å‹
  --epochs 200 \             # æ›´å¤šè®­ç»ƒè½®æ•°
  --batch-size 16 \          # é€‚å½“çš„batch size
  --lr 5e-5 \                # è¾ƒå°çš„å­¦ä¹ ç‡
  --use-amp                  # æ··åˆç²¾åº¦
```

### åŠ å¿«è®­ç»ƒ
```bash
python3 train.py \
  --model-size small \       # å°æ¨¡å‹
  --batch-size 32 \          # æ›´å¤§batchï¼ˆéœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰
  --use-amp \                # æ··åˆç²¾åº¦
  --num-workers 8            # æ›´å¤šæ•°æ®åŠ è½½çº¿ç¨‹
```

### èŠ‚çœæ˜¾å­˜
```bash
python3 train.py \
  --model-size small \
  --batch-size 4 \           # å°batch
  --use-amp \                # æ··åˆç²¾åº¦
  --num-workers 2
```

## ğŸ› æ•…éšœæ’é™¤

### OOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰
- å‡å° `--batch-size`
- ä½¿ç”¨ `--use-amp`
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹ `--model-size small`

### è®­ç»ƒlossä¸ä¸‹é™
- æ£€æŸ¥æ•°æ®é›†è´¨é‡
- å°è¯•ä¸åŒå­¦ä¹ ç‡ï¼ˆ1e-4åˆ°1e-5ï¼‰
- å¢åŠ è®­ç»ƒepochs
- ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹

### API 429é”™è¯¯ï¼ˆç”Ÿæˆæ•°æ®é›†æ—¶ï¼‰
- è„šæœ¬ä¼šè‡ªåŠ¨é‡è¯•
- å¯ä»¥ä½¿ç”¨åˆæˆæ•°æ®é›†ä»£æ›¿ï¼š`create_synthetic_dataset.py`
- æˆ–è€…å‡æ…¢ç”Ÿæˆé€Ÿåº¦

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒLoss
- åˆå§‹: ~0.5-1.0
- 10 epochs: ~0.1-0.3
- 50 epochs: ~0.05-0.15
- 100 epochs: ~0.02-0.10

### ç”Ÿæˆè´¨é‡
- **10 epochs**: åŸºæœ¬å½¢çŠ¶
- **50 epochs**: å¯è¯†åˆ«ç»“æ„
- **100 epochs**: è¾ƒå¥½è´¨é‡
- **200+ epochs**: æœ€ä½³è´¨é‡

## ğŸ“ ä¸‹ä¸€æ­¥

1. **å¾®è°ƒæ¨¡å‹**: åŸºäºç”Ÿæˆç»“æœè°ƒæ•´è®­ç»ƒå‚æ•°
2. **æ‰©å±•æ•°æ®é›†**: ç”Ÿæˆæ›´å¤šæ ·æœ¬ï¼ˆ2000-5000ï¼‰
3. **æ·»åŠ æ¡ä»¶**: å®ç°æ–‡æœ¬æ¡ä»¶ç”Ÿæˆ
4. **é›†æˆåˆ°Server**: å°†æ¨¡å‹é›†æˆåˆ°Mine Builder 2 Server

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

é‡åˆ°é—®é¢˜è¯·æ£€æŸ¥ï¼š
1. `test_system.py` - ç³»ç»Ÿæµ‹è¯•
2. `README_ML.md` - è¯¦ç»†æ–‡æ¡£
3. è®­ç»ƒæ—¥å¿— - `outputs/` ç›®å½•

## ğŸ‰ å®Œæˆï¼

ç°åœ¨ä½ å·²ç»æœ‰äº†ï¼š
âœ… å®Œæ•´çš„æ•°æ®é›†ï¼ˆ1000ä¸ªæ ·æœ¬ï¼‰
âœ… æœ€æ–°çš„DiTæ¨¡å‹æ¶æ„
âœ… è®­ç»ƒå’Œæ¨ç†è„šæœ¬
âœ… GPUåŠ é€Ÿæ”¯æŒ
âœ… æ··åˆç²¾åº¦è®­ç»ƒ

å¼€å§‹è®­ç»ƒä½ çš„Minecraftå»ºç­‘ç”Ÿæˆæ¨¡å‹å§ï¼ğŸš€
